{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import  DecisionTreeClassifier\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Import Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Undergrad</th>\n",
       "      <th>Marital.Status</th>\n",
       "      <th>Taxable.Income</th>\n",
       "      <th>City.Population</th>\n",
       "      <th>Work.Experience</th>\n",
       "      <th>Urban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NO</td>\n",
       "      <td>Single</td>\n",
       "      <td>68833</td>\n",
       "      <td>50047</td>\n",
       "      <td>10</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YES</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>33700</td>\n",
       "      <td>134075</td>\n",
       "      <td>18</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NO</td>\n",
       "      <td>Married</td>\n",
       "      <td>36925</td>\n",
       "      <td>160205</td>\n",
       "      <td>30</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YES</td>\n",
       "      <td>Single</td>\n",
       "      <td>50190</td>\n",
       "      <td>193264</td>\n",
       "      <td>15</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NO</td>\n",
       "      <td>Married</td>\n",
       "      <td>81002</td>\n",
       "      <td>27533</td>\n",
       "      <td>28</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>YES</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>76340</td>\n",
       "      <td>39492</td>\n",
       "      <td>7</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>YES</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>69967</td>\n",
       "      <td>55369</td>\n",
       "      <td>2</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>NO</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>47334</td>\n",
       "      <td>154058</td>\n",
       "      <td>0</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>YES</td>\n",
       "      <td>Married</td>\n",
       "      <td>98592</td>\n",
       "      <td>180083</td>\n",
       "      <td>17</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>NO</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>96519</td>\n",
       "      <td>158137</td>\n",
       "      <td>16</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Undergrad Marital.Status  Taxable.Income  City.Population  \\\n",
       "0          NO         Single           68833            50047   \n",
       "1         YES       Divorced           33700           134075   \n",
       "2          NO        Married           36925           160205   \n",
       "3         YES         Single           50190           193264   \n",
       "4          NO        Married           81002            27533   \n",
       "..        ...            ...             ...              ...   \n",
       "595       YES       Divorced           76340            39492   \n",
       "596       YES       Divorced           69967            55369   \n",
       "597        NO       Divorced           47334           154058   \n",
       "598       YES        Married           98592           180083   \n",
       "599        NO       Divorced           96519           158137   \n",
       "\n",
       "     Work.Experience Urban  \n",
       "0                 10   YES  \n",
       "1                 18   YES  \n",
       "2                 30   YES  \n",
       "3                 15   YES  \n",
       "4                 28    NO  \n",
       "..               ...   ...  \n",
       "595                7   YES  \n",
       "596                2   YES  \n",
       "597                0   YES  \n",
       "598               17    NO  \n",
       "599               16    NO  \n",
       "\n",
       "[600 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud=pd.read_csv('Fraud_check.csv')\n",
    "fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 600 entries, 0 to 599\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Undergrad        600 non-null    object\n",
      " 1   Marital.Status   600 non-null    object\n",
      " 2   Taxable.Income   600 non-null    int64 \n",
      " 3   City.Population  600 non-null    int64 \n",
      " 4   Work.Experience  600 non-null    int64 \n",
      " 5   Urban            600 non-null    object\n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 28.2+ KB\n"
     ]
    }
   ],
   "source": [
    "fraud.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Undergrad          0\n",
       "Marital.Status     0\n",
       "Taxable.Income     0\n",
       "City.Population    0\n",
       "Work.Experience    0\n",
       "Urban              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Undergrad</th>\n",
       "      <th>Marital.Status</th>\n",
       "      <th>Taxable.Income</th>\n",
       "      <th>City.Population</th>\n",
       "      <th>Work.Experience</th>\n",
       "      <th>Urban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>YES</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>312</td>\n",
       "      <td>217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55208.375000</td>\n",
       "      <td>108747.368333</td>\n",
       "      <td>15.558333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26204.827597</td>\n",
       "      <td>49850.075134</td>\n",
       "      <td>8.842147</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10003.000000</td>\n",
       "      <td>25779.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32871.500000</td>\n",
       "      <td>66966.750000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55074.500000</td>\n",
       "      <td>106493.500000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78611.750000</td>\n",
       "      <td>150114.250000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>99619.000000</td>\n",
       "      <td>199778.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Undergrad Marital.Status  Taxable.Income  City.Population  \\\n",
       "count        600            600      600.000000       600.000000   \n",
       "unique         2              3             NaN              NaN   \n",
       "top          YES         Single             NaN              NaN   \n",
       "freq         312            217             NaN              NaN   \n",
       "mean         NaN            NaN    55208.375000    108747.368333   \n",
       "std          NaN            NaN    26204.827597     49850.075134   \n",
       "min          NaN            NaN    10003.000000     25779.000000   \n",
       "25%          NaN            NaN    32871.500000     66966.750000   \n",
       "50%          NaN            NaN    55074.500000    106493.500000   \n",
       "75%          NaN            NaN    78611.750000    150114.250000   \n",
       "max          NaN            NaN    99619.000000    199778.000000   \n",
       "\n",
       "        Work.Experience Urban  \n",
       "count        600.000000   600  \n",
       "unique              NaN     2  \n",
       "top                 NaN   YES  \n",
       "freq                NaN   302  \n",
       "mean          15.558333   NaN  \n",
       "std            8.842147   NaN  \n",
       "min            0.000000   NaN  \n",
       "25%            8.000000   NaN  \n",
       "50%           15.000000   NaN  \n",
       "75%           24.000000   NaN  \n",
       "max           30.000000   NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Undergrad          object\n",
       "Marital.Status     object\n",
       "Taxable.Income      int64\n",
       "City.Population     int64\n",
       "Work.Experience     int64\n",
       "Urban              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.value_counts of 0        Single\n",
       "1      Divorced\n",
       "2       Married\n",
       "3        Single\n",
       "4       Married\n",
       "         ...   \n",
       "595    Divorced\n",
       "596    Divorced\n",
       "597    Divorced\n",
       "598     Married\n",
       "599    Divorced\n",
       "Name: Marital.Status, Length: 600, dtype: object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud['Marital.Status'].value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Undergrad</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Taxable_Income</th>\n",
       "      <th>City_Population</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Urban</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NO</td>\n",
       "      <td>Single</td>\n",
       "      <td>68833</td>\n",
       "      <td>50047</td>\n",
       "      <td>10</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YES</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>33700</td>\n",
       "      <td>134075</td>\n",
       "      <td>18</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NO</td>\n",
       "      <td>Married</td>\n",
       "      <td>36925</td>\n",
       "      <td>160205</td>\n",
       "      <td>30</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YES</td>\n",
       "      <td>Single</td>\n",
       "      <td>50190</td>\n",
       "      <td>193264</td>\n",
       "      <td>15</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NO</td>\n",
       "      <td>Married</td>\n",
       "      <td>81002</td>\n",
       "      <td>27533</td>\n",
       "      <td>28</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>YES</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>76340</td>\n",
       "      <td>39492</td>\n",
       "      <td>7</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>YES</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>69967</td>\n",
       "      <td>55369</td>\n",
       "      <td>2</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>NO</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>47334</td>\n",
       "      <td>154058</td>\n",
       "      <td>0</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>YES</td>\n",
       "      <td>Married</td>\n",
       "      <td>98592</td>\n",
       "      <td>180083</td>\n",
       "      <td>17</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>NO</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>96519</td>\n",
       "      <td>158137</td>\n",
       "      <td>16</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Undergrad Marital_Status  Taxable_Income  City_Population  \\\n",
       "0          NO         Single           68833            50047   \n",
       "1         YES       Divorced           33700           134075   \n",
       "2          NO        Married           36925           160205   \n",
       "3         YES         Single           50190           193264   \n",
       "4          NO        Married           81002            27533   \n",
       "..        ...            ...             ...              ...   \n",
       "595       YES       Divorced           76340            39492   \n",
       "596       YES       Divorced           69967            55369   \n",
       "597        NO       Divorced           47334           154058   \n",
       "598       YES        Married           98592           180083   \n",
       "599        NO       Divorced           96519           158137   \n",
       "\n",
       "     Work_Experience Urban  \n",
       "0                 10   YES  \n",
       "1                 18   YES  \n",
       "2                 30   YES  \n",
       "3                 15   YES  \n",
       "4                 28    NO  \n",
       "..               ...   ...  \n",
       "595                7   YES  \n",
       "596                2   YES  \n",
       "597                0   YES  \n",
       "598               17    NO  \n",
       "599               16    NO  \n",
       "\n",
       "[600 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.rename(columns = {'Marital.Status':'Marital_Status', 'Taxable.Income':'Taxable_Income',\n",
    "                        'City.Population':'City_Population','Work.Experience':'Work_Experience'}, inplace = True)\n",
    "fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud['Undergrad']=le.fit_transform(fraud.Undergrad)\n",
    "fraud['Marital_Status']=le.fit_transform(fraud.Marital_Status)\n",
    "fraud['Urban']=le.fit_transform(fraud.Urban)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Undergrad          int32\n",
       "Marital_Status     int32\n",
       "Taxable_Income     int64\n",
       "City_Population    int64\n",
       "Work_Experience    int64\n",
       "Urban              int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud[\"Tax\"] = pd.cut(fraud[\"Taxable_Income\"], bins = [10000,30000,100000], labels = [\"Risky\", \"Good\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud['Tax']=le.fit_transform(fraud.Tax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    476\n",
       "1    124\n",
       "Name: Tax, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud['Tax'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=fraud.drop('Tax',axis=1)\n",
    "y=fraud.Tax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.15,random_state=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plotting decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_tree(classifier)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.Model Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train=classifier.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.Modal Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score :  1.0\n",
      "-------------------------------------------\n",
      "Confusion Matrix:\n",
      " [[405   0]\n",
      " [  0 105]]\n",
      "-------------------------------------------\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       405\n",
      "           1       1.00      1.00      1.00       105\n",
      "\n",
      "    accuracy                           1.00       510\n",
      "   macro avg       1.00      1.00      1.00       510\n",
      "weighted avg       1.00      1.00      1.00       510\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "print('Accuracy Score : ',accuracy_score(y_train,y_pred_train))\n",
    "print('-------------------------------------------')\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_train,y_pred_train))\n",
    "print('-------------------------------------------')\n",
    "print('Classification Report:\\n',classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score :  1.0\n",
      "-------------------------------------------\n",
      "Confusion Matrix:\n",
      " [[71  0]\n",
      " [ 0 19]]\n",
      "-------------------------------------------\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        71\n",
      "           1       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00        90\n",
      "   macro avg       1.00      1.00      1.00        90\n",
      "weighted avg       1.00      1.00      1.00        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "print('Accuracy Score : ',accuracy_score(y_test,y_pred_test))\n",
    "print('-------------------------------------------')\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_test,y_pred_test))\n",
    "print('-------------------------------------------')\n",
    "print('Classification Report:\\n',classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_classifier=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [10, 120, 230, 340, 450, 560, 670, 780, 890, 1000], 'min_samples_split': [2, 5, 10, 14], 'min_samples_leaf': [1, 2, 4, 6, 8], 'criterion': ['entropy', 'gini']}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt','log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 1000,10)]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10,14]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4,6,8]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "              'criterion':['entropy','gini']}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_search_cv=RandomizedSearchCV(estimator=rd_classifier, param_distributions=random_grid,\n",
    "                                    random_state=23,n_iter=100,n_jobs=-1,cv=3,verbose=2)\n",
    "random_final=random_search_cv.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': ['gini'], 'max_depth': [450], 'max_features': ['sqrt'], 'min_samples_leaf': [8, 10, 12], 'min_samples_split': [8, 9, 10, 11, 12], 'n_estimators': [1400, 1500, 1600, 1700, 1800]}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'criterion': [random_final.best_params_['criterion']],\n",
    "    'max_depth': [random_final.best_params_['max_depth']],\n",
    "    'max_features': [random_final.best_params_['max_features']],\n",
    "    'min_samples_leaf': [random_final.best_params_['min_samples_leaf'], \n",
    "                         random_final.best_params_['min_samples_leaf']+2, \n",
    "                         random_final.best_params_['min_samples_leaf'] + 4],\n",
    "    'min_samples_split': [random_final.best_params_['min_samples_split'] - 2,\n",
    "                          random_final.best_params_['min_samples_split'] - 1,\n",
    "                          random_final.best_params_['min_samples_split'], \n",
    "                          random_final.best_params_['min_samples_split'] +1,\n",
    "                          random_final.best_params_['min_samples_split'] + 2],\n",
    "    'n_estimators': [random_final.best_params_['n_estimators'] - 200, random_final.best_params_['n_estimators'] - 100, \n",
    "                     random_final.best_params_['n_estimators'], \n",
    "                     random_final.best_params_['n_estimators'] + 100, random_final.best_params_['n_estimators'] + 200]\n",
    "}\n",
    "\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 75 candidates, totalling 375 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini'], 'max_depth': [450],\n",
       "                         'max_features': ['sqrt'],\n",
       "                         'min_samples_leaf': [8, 10, 12],\n",
       "                         'min_samples_split': [8, 9, 10, 11, 12],\n",
       "                         'n_estimators': [1400, 1500, 1600, 1700, 1800]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_cv=GridSearchCV(estimator=rd_classifier,param_grid=param_grid,n_jobs=-1,verbose=2)\n",
    "grid_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 450,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 8,\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 1400}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_classifier=RandomForestClassifier(n_estimators=1400,criterion='gini',max_depth=450,max_features='sqrt',min_samples_leaf=8,\n",
    "                                    min_samples_split=8,class_weight={0:3,1:1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_classifier=rd_classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing  and Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train=rd_classifier.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score :  1.0\n",
      "-------------------------------------------\n",
      "Confusion Matrix:\n",
      " [[405   0]\n",
      " [  0 105]]\n",
      "-------------------------------------------\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       405\n",
      "           1       1.00      1.00      1.00       105\n",
      "\n",
      "    accuracy                           1.00       510\n",
      "   macro avg       1.00      1.00      1.00       510\n",
      "weighted avg       1.00      1.00      1.00       510\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "print('Accuracy Score : ',accuracy_score(y_train,y_pred_train))\n",
    "print('-------------------------------------------')\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_train,y_pred_train))\n",
    "print('-------------------------------------------')\n",
    "print('Classification Report:\\n',classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test=rd_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score :  1.0\n",
      "-------------------------------------------\n",
      "Confusion Matrix:\n",
      " [[71  0]\n",
      " [ 0 19]]\n",
      "-------------------------------------------\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        71\n",
      "           1       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00        90\n",
      "   macro avg       1.00      1.00      1.00        90\n",
      "weighted avg       1.00      1.00      1.00        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score : ',accuracy_score(y_test,y_pred_test))\n",
    "print('-------------------------------------------')\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_test,y_pred_test))\n",
    "print('-------------------------------------------')\n",
    "print('Classification Report:\\n',classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_classifier=GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [10, 120, 230, 340, 450, 560, 670, 780, 890, 1000], 'min_samples_split': [2, 5, 10, 14], 'min_samples_leaf': [1, 2, 4, 6, 8], 'criterion': ['friedman_mse', 'squared_error', 'mse', 'mae'], 'loss': ['deviance', 'exponential'], 'learning_rate': [0.0, 0.1111111111111111, 0.2222222222222222, 0.3333333333333333, 0.4444444444444444, 0.5555555555555556, 0.6666666666666666, 0.7777777777777777, 0.8888888888888888, 1.0]}\n"
     ]
    }
   ],
   "source": [
    "#loss function\n",
    "loss = ['deviance','exponential']\n",
    "#learning Rate\n",
    "learning_rate = [float(x) for x in np.linspace(start=0,stop=1,num=10)]\n",
    "#criterion\n",
    "criterion= ['friedman_mse', 'squared_error', 'mse', 'mae' ]\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt','log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 1000,10)]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10,14]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4,6,8]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "              'criterion':criterion,\n",
    "              'loss':loss,'learning_rate':learning_rate}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=GradientBoostingClassifier(), n_jobs=-1,\n",
       "                   param_distributions={'criterion': ['friedman_mse',\n",
       "                                                      'squared_error', 'mse',\n",
       "                                                      'mae'],\n",
       "                                        'learning_rate': [0.0,\n",
       "                                                          0.1111111111111111,\n",
       "                                                          0.2222222222222222,\n",
       "                                                          0.3333333333333333,\n",
       "                                                          0.4444444444444444,\n",
       "                                                          0.5555555555555556,\n",
       "                                                          0.6666666666666666,\n",
       "                                                          0.7777777777777777,\n",
       "                                                          0.8888888888888888,\n",
       "                                                          1.0],\n",
       "                                        'loss': ['deviance', 'exponential'],\n",
       "                                        'max_depth': [10, 120, 230, 340, 450,\n",
       "                                                      560, 670, 780, 890,\n",
       "                                                      1000],\n",
       "                                        'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4, 6, 8],\n",
       "                                        'min_samples_split': [2, 5, 10, 14],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=99, verbose=2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv=RandomizedSearchCV(estimator=gd_classifier,param_distributions=random_grid,n_iter=10,cv=3,n_jobs=-1,verbose=2,\n",
    "                             random_state=99)\n",
    "random_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': ['squared_error'], 'max_depth': [780], 'max_features': ['auto'], 'min_samples_leaf': [8, 10, 12], 'min_samples_split': [8, 9, 10, 11, 12], 'n_estimators': [1000, 1100, 1200, 1300, 1400], 'loss': ['deviance'], 'learning_rate': [0.3333333333333333]}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid = {\n",
    "    'criterion': [random_cv.best_params_['criterion']],\n",
    "    'max_depth': [random_cv.best_params_['max_depth']],\n",
    "    'max_features': [random_cv.best_params_['max_features']],\n",
    "    'min_samples_leaf': [random_cv.best_params_['min_samples_leaf'], \n",
    "                         random_cv.best_params_['min_samples_leaf']+2, \n",
    "                         random_cv.best_params_['min_samples_leaf'] + 4],\n",
    "    'min_samples_split': [random_cv.best_params_['min_samples_split'] - 2,\n",
    "                          random_cv.best_params_['min_samples_split'] - 1,\n",
    "                          random_cv.best_params_['min_samples_split'], \n",
    "                          random_cv.best_params_['min_samples_split'] +1,\n",
    "                          random_cv.best_params_['min_samples_split'] + 2],\n",
    "    'n_estimators': [random_cv.best_params_['n_estimators'] - 200, random_cv.best_params_['n_estimators'] - 100, \n",
    "                     random_cv.best_params_['n_estimators'], \n",
    "                     random_cv.best_params_['n_estimators'] + 100, random_cv.best_params_['n_estimators'] + 200],\n",
    "    'loss':[random_cv.best_params_['loss']],\n",
    "    'learning_rate':[random_cv.best_params_['learning_rate']]\n",
    "}\n",
    "\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 75 candidates, totalling 225 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=GradientBoostingClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['squared_error'],\n",
       "                         'learning_rate': [0.3333333333333333],\n",
       "                         'loss': ['deviance'], 'max_depth': [780],\n",
       "                         'max_features': ['auto'],\n",
       "                         'min_samples_leaf': [8, 10, 12],\n",
       "                         'min_samples_split': [8, 9, 10, 11, 12],\n",
       "                         'n_estimators': [1000, 1100, 1200, 1300, 1400]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv=GridSearchCV(estimator=gd_classifier,param_grid=param_grid,cv=3,n_jobs=-1,verbose=2)\n",
    "grid_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'squared_error',\n",
       " 'learning_rate': 0.3333333333333333,\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 780,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 8,\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 1000}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_classifier=GradientBoostingClassifier(criterion= 'squared_error',learning_rate=0.3333333333333333,loss= 'deviance',\n",
    "                                        max_depth = 780,max_features = 'auto',min_samples_leaf = 8,min_samples_split = 8,\n",
    "                                       n_estimators = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='squared_error',\n",
       "                           learning_rate=0.3333333333333333, max_depth=780,\n",
       "                           max_features='auto', min_samples_leaf=8,\n",
       "                           min_samples_split=8, n_estimators=1000)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd_classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing | Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train=gd_classifier.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score :  1.0\n",
      "-------------------------------------------\n",
      "Confusion Matrix:\n",
      " [[405   0]\n",
      " [  0 105]]\n",
      "-------------------------------------------\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       405\n",
      "           1       1.00      1.00      1.00       105\n",
      "\n",
      "    accuracy                           1.00       510\n",
      "   macro avg       1.00      1.00      1.00       510\n",
      "weighted avg       1.00      1.00      1.00       510\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score : ',accuracy_score(y_train,y_pred_train))\n",
    "print('-------------------------------------------')\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_train,y_pred_train))\n",
    "print('-------------------------------------------')\n",
    "print('Classification Report:\\n',classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test=gd_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score :  1.0\n",
      "-------------------------------------------\n",
      "Confusion Matrix:\n",
      " [[71  0]\n",
      " [ 0 19]]\n",
      "-------------------------------------------\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        71\n",
      "           1       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00        90\n",
      "   macro avg       1.00      1.00      1.00        90\n",
      "weighted avg       1.00      1.00      1.00        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score : ',accuracy_score(y_test,y_pred_test))\n",
    "print('-------------------------------------------')\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_test,y_pred_test))\n",
    "print('-------------------------------------------')\n",
    "print('Classification Report:\\n',classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_classifier=AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 288, 377, 466, 555, 644, 733, 822, 911, 1000], 'learning_rate': [0.0, 0.1111111111111111, 0.2222222222222222, 0.3333333333333333, 0.4444444444444444, 0.5555555555555556, 0.6666666666666666, 0.7777777777777777, 0.8888888888888888, 1.0], 'algorithm': ['SAMME', 'SAMME.R']}\n"
     ]
    }
   ],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(200,1000,10)]\n",
    "learning_rate= [float(x) for x in np.linspace(0,1,10)]\n",
    "algorithm=['SAMME', 'SAMME.R']\n",
    "grid={'n_estimators':n_estimators,'learning_rate':learning_rate,'algorithm':algorithm}\n",
    "print(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=AdaBoostClassifier(), n_jobs=-1,\n",
       "             param_grid={'algorithm': ['SAMME', 'SAMME.R'],\n",
       "                         'learning_rate': [0.0, 0.1111111111111111,\n",
       "                                           0.2222222222222222,\n",
       "                                           0.3333333333333333,\n",
       "                                           0.4444444444444444,\n",
       "                                           0.5555555555555556,\n",
       "                                           0.6666666666666666,\n",
       "                                           0.7777777777777777,\n",
       "                                           0.8888888888888888, 1.0],\n",
       "                         'n_estimators': [200, 288, 377, 466, 555, 644, 733,\n",
       "                                          822, 911, 1000]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch=GridSearchCV(estimator=ad_classifier,param_grid=grid,n_jobs=-1,cv=5,verbose=2)\n",
    "gridsearch.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'SAMME',\n",
       " 'learning_rate': 0.1111111111111111,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_classifier=AdaBoostClassifier(algorithm = 'SAMME',learning_rate= 0.1111111111111111,n_estimators=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME', learning_rate=0.1111111111111111,\n",
       "                   n_estimators=200)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing | Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train=ad_classifier.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score :  1.0\n",
      "-------------------------------------------\n",
      "Confusion Matrix:\n",
      " [[405   0]\n",
      " [  0 105]]\n",
      "-------------------------------------------\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       405\n",
      "           1       1.00      1.00      1.00       105\n",
      "\n",
      "    accuracy                           1.00       510\n",
      "   macro avg       1.00      1.00      1.00       510\n",
      "weighted avg       1.00      1.00      1.00       510\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score : ',accuracy_score(y_train,y_pred_train))\n",
    "print('-------------------------------------------')\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_train,y_pred_train))\n",
    "print('-------------------------------------------')\n",
    "print('Classification Report:\\n',classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test=ad_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score :  1.0\n",
      "-------------------------------------------\n",
      "Confusion Matrix:\n",
      " [[71  0]\n",
      " [ 0 19]]\n",
      "-------------------------------------------\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        71\n",
      "           1       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00        90\n",
      "   macro avg       1.00      1.00      1.00        90\n",
      "weighted avg       1.00      1.00      1.00        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score : ',accuracy_score(y_test,y_pred_test))\n",
    "print('-------------------------------------------')\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_test,y_pred_test))\n",
    "print('-------------------------------------------')\n",
    "print('Classification Report:\\n',classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_classifier=XGBClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:50:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing | Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train=xg_classifier.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score :  1.0\n",
      "-------------------------------------------\n",
      "Confusion Matrix:\n",
      " [[405   0]\n",
      " [  0 105]]\n",
      "-------------------------------------------\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       405\n",
      "           1       1.00      1.00      1.00       105\n",
      "\n",
      "    accuracy                           1.00       510\n",
      "   macro avg       1.00      1.00      1.00       510\n",
      "weighted avg       1.00      1.00      1.00       510\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score : ',accuracy_score(y_train,y_pred_train))\n",
    "print('-------------------------------------------')\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_train,y_pred_train))\n",
    "print('-------------------------------------------')\n",
    "print('Classification Report:\\n',classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test=xg_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score :  1.0\n",
      "-------------------------------------------\n",
      "Confusion Matrix:\n",
      " [[71  0]\n",
      " [ 0 19]]\n",
      "-------------------------------------------\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        71\n",
      "           1       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00        90\n",
      "   macro avg       1.00      1.00      1.00        90\n",
      "weighted avg       1.00      1.00      1.00        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score : ',accuracy_score(y_test,y_pred_test))\n",
    "print('-------------------------------------------')\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_test,y_pred_test))\n",
    "print('-------------------------------------------')\n",
    "print('Classification Report:\\n',classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building lightgradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_classifier=LGBMClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing | Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train=lgbm_classifier.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score :  1.0\n",
      "-------------------------------------------\n",
      "Confusion Matrix:\n",
      " [[405   0]\n",
      " [  0 105]]\n",
      "-------------------------------------------\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       405\n",
      "           1       1.00      1.00      1.00       105\n",
      "\n",
      "    accuracy                           1.00       510\n",
      "   macro avg       1.00      1.00      1.00       510\n",
      "weighted avg       1.00      1.00      1.00       510\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score : ',accuracy_score(y_train,y_pred_train))\n",
    "print('-------------------------------------------')\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_train,y_pred_train))\n",
    "print('-------------------------------------------')\n",
    "print('Classification Report:\\n',classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test=lgbm_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score :  1.0\n",
      "-------------------------------------------\n",
      "Confusion Matrix:\n",
      " [[71  0]\n",
      " [ 0 19]]\n",
      "-------------------------------------------\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        71\n",
      "           1       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00        90\n",
      "   macro avg       1.00      1.00      1.00        90\n",
      "weighted avg       1.00      1.00      1.00        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy Score : ',accuracy_score(y_test,y_pred_test))\n",
    "print('-------------------------------------------')\n",
    "print('Confusion Matrix:\\n',confusion_matrix(y_test,y_pred_test))\n",
    "print('-------------------------------------------')\n",
    "print('Classification Report:\\n',classification_report(y_test,y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructed Different Ensemble Techiques along with Decision Tree ,Random forest and saw it is working with different algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
